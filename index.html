<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prerit Gupta</title>
    <script src="https://cdn.tailwindcss.com"></script>
  </head>
  <body class="bg-white text-gray-900 font-sans">
    <!-- Header -->
    <header class="bg-gradient-to-r from-blue-100 to-blue-200 shadow p-8">
      <div class="max-w-5xl mx-auto flex flex-col md:flex-row items-center md:justify-between gap-6">
        <div>
          <h1 class="text-4xl font-bold text-gray-900">Prerit Gupta</h1>
          <p class="text-lg text-gray-700 mt-2">Ph.D. Student in Computer Science | Purdue University</p>
          <p class="text-md text-gray-600">Human-Centered AI · Affective Computing · Embodied Interaction</p>
        </div>
        <div class="w-32 h-32 overflow-hidden rounded-full shadow-md border border-gray-300">
          <img src="Profile_image.jpg" alt="Prerit Gupta" class="w-full h-full object-cover" />
        </div>
      </div>
    </header>

    <!-- About Section -->
    <section class="py-12 px-6 max-w-5xl mx-auto">
      <h2 class="text-2xl font-semibold mb-4">About Me</h2>
      <p class="text-gray-700 leading-relaxed text-lg">
        I am a Ph.D. student in the Department of Computer Science at Purdue University, advised by Prof. Aniket Bera. My research lies at the intersection of affective computing, multi-modal learning, and human motion generation. I focus on building emotionally expressive and context-aware virtual agents that interact naturally with humans in real time. Previously, I earned my B.Tech and M.Tech in Electronics and Electrical Communications from IIT Kharagpur.
      </p>
    </section>

    <!-- Publications Section -->
    <section class="bg-gray-50 py-12 px-6">
      <div class="max-w-5xl mx-auto">
        <h2 class="text-2xl font-semibold mb-4">Selected Publications</h2>
        <ul class="list-disc ml-6 space-y-3 text-gray-800 text-lg">
     <li>
  Prerit Gupta, Jason Alexander Fotso-Puepi, Zhengyuan Li, Jay Mehta, and Aniket Bera. 
  <a href="https://gprerit96.github.io/mdd-page" target="_blank">
    MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation
  </a>. 
  <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2025.</em>
</li>
          <li>
            Prerit Gupta, Shourya Verma, Ananth Grama, and Aniket Bera. DuetRAG: Multi-Modal 3D Motion Duet Dance Generation via Retrieval-Augmented Feature Guided Contrastive Rectified Flow. <em>Under Review at IEEE/CVF Winter Conference for Applications in Computer Vision, 2026.</em>
          </li>
           <li>
            Prerit Gupta, Shourya Verma, Ananth Grama, and Aniket Bera. Unified Multi-Modal Interactive and Reactive 3D Motion Generation via Rectified Flow. <em>Under Review at International Conference for Learning Representations, 2026.</em>
          </li>
        </ul>
      </div>
    </section>

    <!-- Contact Section -->
    <section class="bg-blue-50 py-12 px-6">
      <div class="max-w-5xl mx-auto">
        <h2 class="text-2xl font-semibold mb-4">Contact</h2>
        <div class="text-lg text-gray-700 space-y-2">
          <p>Email: <a href="mailto:gupta596@purdue.edu" class="text-blue-700 underline">gupta596@purdue.edu</a></p>
          <p>GitHub: <a href="https://github.com/gprerit96" class="text-blue-700 underline">github.com/gprerit96</a></p>
          <p>LinkedIn: <a href="https://linkedin.com/in/gprerit" class="text-blue-700 underline">linkedin.com/in/gprerit</a></p>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-100 text-center py-6 text-sm text-gray-500">
      &copy; 2025 Prerit Gupta. All rights reserved.
    </footer>
  </body>
</html>
