<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prerit Gupta</title>
    <script src="https://cdn.tailwindcss.com"></script>
  </head>
  <body class="bg-white text-gray-900 font-sans">
    <!-- Header -->
    <header class="bg-gradient-to-r from-blue-100 to-blue-200 shadow p-8">
      <div class="max-w-5xl mx-auto flex flex-col md:flex-row items-center md:justify-between gap-6">
        <div>
          <h1 class="text-4xl font-bold text-gray-900">Prerit Gupta</h1>
          <p class="text-lg text-gray-700 mt-2">Ph.D. Student in Computer Science | Purdue University</p>
          <p class="text-md text-gray-600">Human-Centered AI · Affective Computing · Embodied Interaction</p>
        </div>
        
        <!-- Profile Image + Resume Link -->
        <div class="flex flex-col items-center">
          <div class="w-32 h-32 overflow-hidden rounded-full shadow-md border border-gray-300">
            <img src="Profile_image.jpg" alt="Prerit Gupta" class="w-full h-full object-cover" />
          </div>
          <a 
            href="https://drive.google.com/file/d/1_3cQCp8-ufi9YRNoik-WtUQigJ3XfnUC/view?usp=sharing" 
            target="_blank"
            class="mt-3 text-blue-600 hover:text-blue-800 font-medium text-sm underline"
          >
            Download Resume (PDF)
          </a>
        </div>
      </div>
    </header>

    <!-- About Section -->
    <section class="py-12 px-6 max-w-5xl mx-auto">
      <h2 class="text-2xl font-semibold mb-4">About Me</h2>
      <p class="text-gray-700 leading-relaxed text-lg">
        I am a Ph.D. student in Computer Science at Purdue University, working in the IDEAS Lab under the supervision of Prof. Aniket Bera. My research lies at the intersection of interactive human motion graphics, affective computing, and multimodal generative AI.

My current work explores how multimodal learning frameworks—combining motion, text and music — can enable better contextualized and controlled generation. This includes building datasets and models for interactive and reactive motion generation, and context-sensitive human–AI interaction in immersive environments such as VR. Some of the upcoming projects I have been working on are related to exploring motion editing and long-term generation for two-person generation. 
        
Previously, I earned my B.Tech and M.Tech in Electronics and Electrical Communications from IIT Kharagpur.
      </p>
    </section>

    <!-- Publications Section -->
<section class="bg-gray-50 py-12 px-6">
  <div class="max-w-5xl mx-auto">
    <h2 class="text-2xl font-semibold mb-6">Selected Publications</h2>

    <div class="space-y-6">

      <!-- Publication 1 -->
      <div class="flex gap-5 items-start bg-white p-4 rounded-xl shadow-sm">
        <!-- Thumbnail -->
        <!-- Thumbnail -->
        <a href="https://www.arxiv.org/abs/2509.24099" target="_blank">
          <img src="images/Dualflow_teaser.png"
              alt="DualFlow Thumbnail"
              class="w-52 h-36 object-cover rounded-lg hover:scale-105 transition" />
        </a>
        <!-- Details -->
        <div class="text-gray-800 text-lg">
          <p>
            Prerit Gupta, Shourya Verma, Ananth Grama, and Aniket Bera.
            <em>Unified Multi-Modal Interactive and Reactive 3D Motion Generation via Rectified Flow.</em>
            <em>Accepted at International Conference on Learning Representations (ICLR), 2026.</em>
            <a href="https://www.arxiv.org/abs/2509.24099" target="_blank" class="text-blue-600 text-base no-underline">[link]</a>
          </p>
        </div>
      </div>

      <!-- Publication 2 -->
      <div class="flex gap-5 items-start bg-white p-4 rounded-xl shadow-sm">
        <!-- Thumbnail -->
        <img src="images/MDD_teaser.png" alt="MDD Thumbnail" class="w-36 h-24 object-cover rounded-lg" />

        <!-- Details -->
        <div class="text-gray-800 text-lg">
          <p>
            Prerit Gupta, Jason Alexander Fotso-Puepi, Zhengyuan Li, Jay Mehta, and Aniket Bera.
            <em>MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation.</em>
            <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2025.</em>
            <a href="https://gprerit96.github.io/MDD" target="_blank" class="text-blue-600 text-base no-underline">[link]</a>
          </p>
        </div>
      </div>

      <!-- Publication 3 -->
      <div class="flex gap-5 items-start bg-white p-4 rounded-xl shadow-sm">
        <!-- Thumbnail -->
        <img src="images/Seizure_project.png" alt="Neurophysiology Thumbnail" class="w-36 h-24 object-cover rounded-lg" />

        <!-- Details -->
        <div class="text-gray-800 text-lg">
          <p>
            Shatha J Mufti, Shourya Verma, Jhon Martinez, Prerit Gupta, Aniket Bera, Ananth Grama, Riyi Shi and Aniket Bera.
            <em>Unravelling the Dynamics of Seizure-Like Activity in Neuronal Networks using Machine Learning.</em>
            <em>Journal of Neurophysiology 134 (6), 1969-1993.</em>
            <a href="https://journals.physiology.org/doi/full/10.1152/jn.00320.2025" target="_blank" class="text-blue-600 text-base no-underline">[link]</a>
          </p>
        </div>
      </div>

    </div>
  </div>
</section>


    <!-- Publications Section -->
    <!-- <section class="bg-gray-50 py-12 px-6">
      <div class="max-w-5xl mx-auto">
        <h2 class="text-2xl font-semibold mb-4">Selected Publications</h2>
        <ul class="list-disc ml-6 space-y-3 text-gray-800 text-lg">
     
   <li>
  Prerit Gupta, Shourya Verma, Ananth Grama, and Aniket Bera. 
  <em>
    Unified Multi-Modal Interactive and Reactive 3D Motion Generation via Rectified Flow.
  </em> 
  <em>Accepted at International Conference on Learning Representations (ICLR), 2026.</em>
    <a href="https://www.arxiv.org/abs/2509.24099" target="_blank" style="font-size: 0.9em; color: #0077cc; text-decoration: none;">
    [link]
  </a>
  </li>       
  <li>
  Prerit Gupta, Jason Alexander Fotso-Puepi, Zhengyuan Li, Jay Mehta, and Aniket Bera. 
  <em>
    MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation.
  </em> 
  <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2025.</em>
       <a href="https://gprerit96.github.io/MDD" target="_blank" style="font-size: 0.9em; color: #0077cc; text-decoration: none;">
    [link]
  </a>
</li>
  <li>
  Shatha J Mufti, Shourya Verma, Jhon Martinez, Prerit Gupta, Aniket Bera, Ananth Grama, Riyi Shi and Aniket Bera. 
  <em>
    Unravelling the Dynamics of Seizure-Like Activity in Neuronal Networks using Machine Learning.
  </em> 
  <em>Journal of Neurophysiology 134 (6), 1969-1993.</em>
       <a href="https://journals.physiology.org/doi/full/10.1152/jn.00320.2025" target="_blank" style="font-size: 0.9em; color: #0077cc; text-decoration: none;">
    [link]
  </a>
</li> -->

    

        </ul>
      </div>
    </section>

    <!-- Contact Section -->
    <section class="bg-blue-50 py-12 px-6">
      <div class="max-w-5xl mx-auto">
        <h2 class="text-2xl font-semibold mb-4">Contact</h2>
        <div class="text-lg text-gray-700 space-y-2">
          <p>Email: <a href="mailto:gupta596@purdue.edu" class="text-blue-700 underline">gupta596@purdue.edu</a></p>
          <p>GitHub: <a href="https://github.com/gprerit96" class="text-blue-700 underline">github.com/gprerit96</a></p>
          <p>LinkedIn: <a href="https://linkedin.com/in/gprerit" class="text-blue-700 underline">linkedin.com/in/gprerit</a></p>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-100 text-center py-6 text-sm text-gray-500">
      &copy; 2025 Prerit Gupta. All rights reserved.
    </footer>
  </body>
</html>
